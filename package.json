{
  "name": "context-selector-debugger",
  "displayName": "Context Selector Debugger",
  "description": "Granular context selection for AI-powered Go debugging",
  "version": "1.0.0",
  "engines": {
    "vscode": "^1.60.0"
  },
  "categories": [
    "Debuggers",
    "Programming Languages"
  ],
  "activationEvents": [
    "onDebug",
    "onLanguage:go"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "contextSelector.openView",
        "title": "Open Context Selector",
        "icon": "$(settings-gear)"
      },
      {
        "command": "contextSelector.refreshContext",
        "title": "Refresh Context",
        "icon": "$(refresh)"
      },
      {
        "command": "contextSelector.exportContext",
        "title": "Export Selected Context",
        "icon": "$(export)"
      },
            {
        "command": "contextSelector.checkStopped",
        "title": "Check If Debugger Stopped",
        "category": "Debug"
      }
    ],
    "viewsContainers": {
      "activitybar": [
        {
          "id": "contextSelector",
          "title": "Context Selector",
          "icon": "$(gear)"
        }
      ]
    },
    "configuration": {
      "title": "Context Selector",
      "properties": {
        "contextSelector.llm.provider": {
          "type": "string",
          "enum": ["openai", "anthropic", "azure", "custom"],
          "default": "openai",
          "description": "LLM provider for context analysis"
        },
        "contextSelector.llm.openaiApiKey": {
          "type": "string",
          "default": "",
          "description": "OpenAI API key"
        },
        "contextSelector.llm.anthropicApiKey": {
          "type": "string",
          "default": "",
          "description": "Anthropic API key"
        },
        "contextSelector.llm.model": {
          "type": "string",
          "default": "gpt-4",
          "description": "Model to use for analysis"
        },
        "contextSelector.llm.temperature": {
          "type": "number",
          "default": 0.3,
          "description": "Temperature for LLM responses"
        },
        "contextSelector.llm.maxTokens": {
          "type": "number",
          "default": 2000,
          "description": "Maximum tokens in response"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run package",
    "compile": "webpack --config webpack.config.js",
    "watch": "webpack --watch --config webpack.config.js",
    "package": "webpack --mode production --devtool hidden-source-map"
  },
  "dependencies": {
    "node-fetch": "^2.6.7"
  },
  "devDependencies": {
    "@types/node": "^16.18.126",
    "@types/node-fetch": "^2.6.3",
    "@types/vscode": "^1.60.0",
    "ts-loader": "^9.3.0",
    "typescript": "^4.9.5",
    "webpack": "^5.73.0",
    "webpack-cli": "^4.10.0"
  }
}